{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d8abd329f241a1",
   "metadata": {},
   "source": [
    "### ДЗ 5.8\n",
    "Функции для работы с векторами и матрицами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_scalar_product(x, y):\n",
    "    return sum(x_i * y_i for x_i, y_i in zip(x, y))  # <x; y>\n",
    "\n",
    "def matrix_transposition(A):\n",
    "    return [[A[j][i] for j in range(len(A))] for i in range(len(A[0]))]  # A^T\n",
    "\n",
    "def get_matrix_addition(A, B):\n",
    "    return np.array(A) + np.array(B) # A + B\n",
    "\n",
    "def matrix_vector_product(A, y):\n",
    "    return [sum(A[i][j] * y[j] for j in range(len(y))) for i in range(len(A))]  # A * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1210d9f7bf5d7e4",
   "metadata": {},
   "source": [
    "Определим функцию и её градиент в общем виде:\n",
    "$$f(y) = \\langle Ay; y \\rangle - 2\\langle b; y \\rangle$$\n",
    "$$\\nabla f(y) = (A + A^T)y - 2b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2563af5430984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(y, A, b):\n",
    "    return get_scalar_product(matrix_vector_product(A, y), y) - 2 * get_scalar_product(b, y)  # f(y) = <A * y; y> - 2 * <b; y>\n",
    "\n",
    "\n",
    "def gradient(y, A, b):\n",
    "    At = matrix_transposition(A)  # A^T\n",
    "    A_p_At = get_matrix_addition(A, At)  # A + A^T\n",
    "    A_p_At_y_product = matrix_vector_product(A_p_At, y)  # (A + A^T) * y\n",
    "    return [x_i - 2 * b_i for x_i, b_i in zip(A_p_At_y_product, b)]  # grad f(y) = (A + A^T) * y - 2 * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a12064cba939e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(y_k, A, b):\n",
    "    grad = gradient(y_k, A, b)  # grad f(y)\n",
    "    num = get_scalar_product(grad, grad)  # <grad f(y), grad f(y)>\n",
    "    At = matrix_transposition(A)  # A^T\n",
    "    A_p_At = get_matrix_addition(A, At)  # A + A^T\n",
    "    A_p_At_grad_product = matrix_vector_product(A_p_At, grad)  # (A + A^T) * grad f(y)\n",
    "    den = get_scalar_product(A_p_At_grad_product, grad)  # <(A + A^T) * grad f(y), grad f(y)>\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a130a18f45e1dd",
   "metadata": {},
   "source": [
    "Определим функцию градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "938a2012333fab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(func, grad, y_0, A, b, epsilon=0.0000000001):\n",
    "    y_k = y_0\n",
    "    for k in range(1000):\n",
    "        grad_f_k = grad(y_k, A, b)\n",
    "        alpha_k = learning_rate(y_k, A, b)\n",
    "        y_kp1 = [y_k[j] - alpha_k * grad_f_k[j] for j in range(len(y_k))]\n",
    "        if abs(func(y_kp1, A, b) - func(y_k, A, b)) < epsilon:\n",
    "            break\n",
    "        y_k = y_kp1\n",
    "    return y_k, func(y_k, A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecae2ae2e4237c",
   "metadata": {},
   "source": [
    "Проинициализируем матрицу **A**, вектор **b** и нулевую начальную точку **Y0**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18fb3a3cf23faa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[4, -1, 0, -1, 0, 0],\n",
    "     [-1, 4, -1, 0, -1, 0],\n",
    "     [0, -1, 4, 0, 0, -1],\n",
    "     [-1, 0, 0, 4, -1, 0],\n",
    "     [0, -1, 0, -1, 4, -1],\n",
    "     [0, 0, -1, 0, -1, 4]]\n",
    "\n",
    "b = [0, 5, 0, 6, -2, 6]\n",
    "\n",
    "y_0 = [0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ada205ebe8588",
   "metadata": {},
   "source": [
    "С помощью метода градиентого спуска найдём точку локального минимума, значение функции в ней, а также Евклидову норму радиус-вектора этой точки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58e032467582057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точка лок. минимума Y*: [np.float64(1.0), np.float64(2.0), np.float64(1.0), np.float64(2.0), np.float64(1.0), np.float64(2.0)], значение функции f(Y*): -32.0\n",
      "Евклидова норма радиус-вектора Y*: 3.873\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "y_min, f_min = gradient_descent(function, gradient, y_0, A, b)\n",
    "y_norm = sqrt(sum([y_i ** 2 for y_i in y_min]))\n",
    "\n",
    "print(f\"Точка лок. минимума Y*: {[round(y_i, 3) for y_i in y_min]}, значение функции f(Y*): {round(f_min, 3)}\")\n",
    "print(f\"Евклидова норма радиус-вектора Y*: {round(y_norm, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
